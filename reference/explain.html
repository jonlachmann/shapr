<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Explain the output of machine learning models with more accurately estimated Shapley values — explain • shapr</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Explain the output of machine learning models with more accurately estimated Shapley values — explain"><meta property="og:description" content="Computes dependence-aware Shapley values for observations in x_explain from the specified
model by using the method specified in approach to estimate the conditional expectation."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">shapr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.2.3.9200</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Vignettes

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/understanding_shapr.html">General usage of shapr</a>
    </li>
    <li>
      <a href="../articles/understanding_shapr_vaeac.html">Advanced usage of the `vaeac` approach</a>
    </li>
    <li>
      <a href="../articles/understanding_shapr_regression.html">The separate and surrogate regression approches</a>
    </li>
  </ul></li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Manual</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/NorskRegnesentral/shapr/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Explain the output of machine learning models with more accurately estimated Shapley values</h1>
    <small class="dont-index">Source: <a href="https://github.com/NorskRegnesentral/shapr/blob/master/R/explain.R" class="external-link"><code>R/explain.R</code></a></small>
    <div class="hidden name"><code>explain.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Computes dependence-aware Shapley values for observations in <code>x_explain</code> from the specified
<code>model</code> by using the method specified in <code>approach</code> to estimate the conditional expectation.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">explain</span><span class="op">(</span></span>
<span>  <span class="va">model</span>,</span>
<span>  <span class="va">x_explain</span>,</span>
<span>  <span class="va">x_train</span>,</span>
<span>  <span class="va">approach</span>,</span>
<span>  <span class="va">prediction_zero</span>,</span>
<span>  n_combinations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  group <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  keep_samp_for_vS <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  predict_model <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  get_model_specs <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  MSEv_uniform_comb_weights <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  timing <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  verbose <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>The model whose predictions we want to explain.
Run <code><a href="get_supported_models.html">get_supported_models()</a></code>
for a table of which models <code>explain</code> supports natively. Unsupported models
can still be explained by passing <code>predict_model</code> and (optionally) <code>get_model_specs</code>,
see details for more information.</p></dd>


<dt id="arg-x-explain">x_explain<a class="anchor" aria-label="anchor" href="#arg-x-explain"></a></dt>
<dd><p>A matrix or data.frame/data.table.
Contains the the features, whose predictions ought to be explained.</p></dd>


<dt id="arg-x-train">x_train<a class="anchor" aria-label="anchor" href="#arg-x-train"></a></dt>
<dd><p>Matrix or data.frame/data.table.
Contains the data used to estimate the (conditional) distributions for the features
needed to properly estimate the conditional expectations in the Shapley formula.</p></dd>


<dt id="arg-approach">approach<a class="anchor" aria-label="anchor" href="#arg-approach"></a></dt>
<dd><p>Character vector of length <code>1</code> or one less than the number of features.
All elements should, either be <code>"gaussian"</code>, <code>"copula"</code>, <code>"empirical"</code>, <code>"ctree"</code>, <code>"vaeac"</code>,
<code>"categorical"</code>, <code>"timeseries"</code>, <code>"independence"</code>, <code>"regression_separate"</code>, or <code>"regression_surrogate"</code>.
The two regression approaches can not be combined with any other approach. See details for more information.</p></dd>


<dt id="arg-prediction-zero">prediction_zero<a class="anchor" aria-label="anchor" href="#arg-prediction-zero"></a></dt>
<dd><p>Numeric.
The prediction value for unseen data, i.e. an estimate of the expected prediction without conditioning on any
features.
Typically we set this value equal to the mean of the response variable in our training data, but other choices
such as the mean of the predictions in the training data are also reasonable.</p></dd>


<dt id="arg-n-combinations">n_combinations<a class="anchor" aria-label="anchor" href="#arg-n-combinations"></a></dt>
<dd><p>Integer.
If <code>group = NULL</code>, <code>n_combinations</code> represents the number of unique feature combinations to sample.
If <code>group != NULL</code>, <code>n_combinations</code> represents the number of unique group combinations to sample.
If <code>n_combinations = NULL</code>, the exact method is used and all combinations are considered.
The maximum number of combinations equals <code>2^m</code>, where <code>m</code> is the number of features.</p></dd>


<dt id="arg-group">group<a class="anchor" aria-label="anchor" href="#arg-group"></a></dt>
<dd><p>List.
If <code>NULL</code> regular feature wise Shapley values are computed.
If provided, group wise Shapley values are computed. <code>group</code> then has length equal to
the number of groups. The list element contains character vectors with the features included
in each of the different groups.</p></dd>


<dt id="arg-n-samples">n_samples<a class="anchor" aria-label="anchor" href="#arg-n-samples"></a></dt>
<dd><p>Positive integer.
Indicating the maximum number of samples to use in the
Monte Carlo integration for every conditional expectation. See also details.</p></dd>


<dt id="arg-n-batches">n_batches<a class="anchor" aria-label="anchor" href="#arg-n-batches"></a></dt>
<dd><p>Positive integer (or NULL).
Specifies how many batches the total number of feature combinations should be split into when calculating the
contribution function for each test observation.
The default value is NULL which uses a reasonable trade-off between RAM allocation and computation speed,
which depends on <code>approach</code> and <code>n_combinations</code>.
For models with many features, increasing the number of batches reduces the RAM allocation significantly.
This typically comes with a small increase in computation time.</p></dd>


<dt id="arg-seed">seed<a class="anchor" aria-label="anchor" href="#arg-seed"></a></dt>
<dd><p>Positive integer.
Specifies the seed before any randomness based code is being run.
If <code>NULL</code> the seed will be inherited from the calling environment.</p></dd>


<dt id="arg-keep-samp-for-vs">keep_samp_for_vS<a class="anchor" aria-label="anchor" href="#arg-keep-samp-for-vs"></a></dt>
<dd><p>Logical.
Indicates whether the samples used in the Monte Carlo estimation of v_S should be returned
(in <code>internal$output</code>)</p></dd>


<dt id="arg-predict-model">predict_model<a class="anchor" aria-label="anchor" href="#arg-predict-model"></a></dt>
<dd><p>Function.
The prediction function used when <code>model</code> is not natively supported.
(Run <code><a href="get_supported_models.html">get_supported_models()</a></code> for a list of natively supported
models.)
The function must have two arguments, <code>model</code> and <code>newdata</code> which specify, respectively, the model
and a data.frame/data.table to compute predictions for. The function must give the prediction as a numeric vector.
<code>NULL</code> (the default) uses functions specified internally.
Can also be used to override the default function for natively supported model classes.</p></dd>


<dt id="arg-get-model-specs">get_model_specs<a class="anchor" aria-label="anchor" href="#arg-get-model-specs"></a></dt>
<dd><p>Function.
An optional function for checking model/data consistency when <code>model</code> is not natively supported.
(Run <code><a href="get_supported_models.html">get_supported_models()</a></code> for a list of natively supported
models.)
The function takes <code>model</code> as argument and provides a list with 3 elements:</p><dl><dt>labels</dt>
<dd><p>Character vector with the names of each feature.</p></dd>

<dt>classes</dt>
<dd><p>Character vector with the classes of each features.</p></dd>

<dt>factor_levels</dt>
<dd><p>Character vector with the levels for any categorical features.</p></dd>


</dl><p>If <code>NULL</code> (the default) internal functions are used for natively supported model classes, and the checking is
disabled for unsupported model classes.
Can also be used to override the default function for natively supported model classes.</p></dd>


<dt id="arg-msev-uniform-comb-weights">MSEv_uniform_comb_weights<a class="anchor" aria-label="anchor" href="#arg-msev-uniform-comb-weights"></a></dt>
<dd><p>Logical. If <code>TRUE</code> (default), then the function weights the combinations
uniformly when computing the MSEv criterion. If <code>FALSE</code>, then the function use the Shapley kernel weights to
weight the combinations when computing the MSEv criterion. Note that the Shapley kernel weights are replaced by the
sampling frequency when not all combinations are considered.</p></dd>


<dt id="arg-timing">timing<a class="anchor" aria-label="anchor" href="#arg-timing"></a></dt>
<dd><p>Logical.
Whether the timing of the different parts of the <code>explain()</code> should saved in the model object.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>An integer specifying the level of verbosity. If <code>0</code>, <code>shapr</code> will stay silent.
If <code>1</code>, it will print information about performance. If <code>2</code>, some additional information will be printed out.
Use <code>0</code> (default) for no verbosity, <code>1</code> for low verbose, and <code>2</code> for high verbose.
TODO: Make this clearer when we end up fixing this and if they should force a progressr bar.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Arguments passed on to <code><a href="setup_approach.html">setup_approach.empirical</a></code>, <code><a href="setup_approach.html">setup_approach.independence</a></code>, <code><a href="setup_approach.html">setup_approach.gaussian</a></code>, <code><a href="setup_approach.html">setup_approach.copula</a></code>, <code><a href="setup_approach.html">setup_approach.ctree</a></code>, <code><a href="setup_approach.html">setup_approach.vaeac</a></code>, <code><a href="setup_approach.html">setup_approach.categorical</a></code>, <code><a href="setup_approach.html">setup_approach.regression_separate</a></code>, <code><a href="setup_approach.html">setup_approach.regression_surrogate</a></code>, <code><a href="setup_approach.html">setup_approach.timeseries</a></code></p><dl><dt><code>empirical.type</code></dt>
<dd><p>Character. (default = <code>"fixed_sigma"</code>)
Should be equal to either <code>"independence"</code>,<code>"fixed_sigma"</code>, <code>"AICc_each_k"</code> <code>"AICc_full"</code>.
TODO: Describe better what the methods do here.</p></dd>

    <dt><code>empirical.eta</code></dt>
<dd><p>Numeric. (default = 0.95)
Needs to be <code>0 &lt; eta &lt;= 1</code>.
Represents the minimum proportion of the total empirical weight that data samples should use.
If e.g. <code>eta = .8</code> we will choose the <code>K</code> samples with the largest weight so that the sum of the weights
accounts for 80\<!-- % of the total weight. -->
<code>eta</code> is the \(\eta\) parameter in equation (15) of Aas et al (2021).</p></dd>

    <dt><code>empirical.fixed_sigma</code></dt>
<dd><p>Positive numeric scalar. (default = 0.1)
Represents the kernel bandwidth in the distance computation used when conditioning on all different combinations.
Only used when <code>empirical.type = "fixed_sigma"</code></p></dd>

    <dt><code>empirical.n_samples_aicc</code></dt>
<dd><p>Positive integer. (default = 1000)
Number of samples to consider in AICc optimization.
Only used for <code>empirical.type</code> is either <code>"AICc_each_k"</code> or <code>"AICc_full"</code>.</p></dd>

    <dt><code>empirical.eval_max_aicc</code></dt>
<dd><p>Positive integer. (default = 20)
Maximum number of iterations when optimizing the AICc.
Only used for <code>empirical.type</code> is either <code>"AICc_each_k"</code> or <code>"AICc_full"</code>.</p></dd>

    <dt><code>empirical.start_aicc</code></dt>
<dd><p>Numeric. (default = 0.1)
Start value of the <code>sigma</code> parameter when optimizing the AICc.
Only used for <code>empirical.type</code> is either <code>"AICc_each_k"</code> or <code>"AICc_full"</code>.</p></dd>

    <dt><code>empirical.cov_mat</code></dt>
<dd><p>Numeric matrix. (Optional, default = NULL)
Containing the covariance matrix of the data generating distribution used to define the Mahalanobis distance.
<code>NULL</code> means it is estimated from <code>x_train</code>.</p></dd>

    <dt><code>internal</code></dt>
<dd><p>Not used.</p></dd>

    <dt><code>gaussian.mu</code></dt>
<dd><p>Numeric vector. (Optional)
Containing the mean of the data generating distribution.
<code>NULL</code> means it is estimated from the <code>x_train</code>.</p></dd>

    <dt><code>gaussian.cov_mat</code></dt>
<dd><p>Numeric matrix. (Optional)
Containing the covariance matrix of the data generating distribution.
<code>NULL</code> means it is estimated from the <code>x_train</code>.</p></dd>

    <dt><code>ctree.mincriterion</code></dt>
<dd><p>Numeric scalar or vector. (default = 0.95)
Either a scalar or vector of length equal to the number of features in the model.
Value is equal to 1 - \(\alpha\) where \(\alpha\) is the nominal level of the conditional independence tests.
If it is a vector, this indicates which value to use when conditioning on various numbers of features.</p></dd>

    <dt><code>ctree.minsplit</code></dt>
<dd><p>Numeric scalar. (default = 20)
Determines minimum value that the sum of the left and right daughter nodes required for a split.</p></dd>

    <dt><code>ctree.minbucket</code></dt>
<dd><p>Numeric scalar. (default = 7)
Determines the minimum sum of weights in a terminal node required for a split</p></dd>

    <dt><code>ctree.sample</code></dt>
<dd><p>Boolean. (default = TRUE)
If TRUE, then the method always samples <code>n_samples</code> observations from the leaf nodes (with replacement).
If FALSE and the number of observations in the leaf node is less than <code>n_samples</code>,
the method will take all observations in the leaf.
If FALSE and the number of observations in the leaf node is more than <code>n_samples</code>,
the method will sample <code>n_samples</code> observations (with replacement).
This means that there will always be sampling in the leaf unless
<code>sample</code> = FALSE AND the number of obs in the node is less than <code>n_samples</code>.</p></dd>

    <dt><code>vaeac.depth</code></dt>
<dd><p>Positive integer (default is <code>3</code>). The number of hidden layers
in the neural networks of the masked encoder, full encoder, and decoder.</p></dd>

    <dt><code>vaeac.width</code></dt>
<dd><p>Positive integer (default is <code>32</code>). The number of neurons in each
hidden layer in the neural networks of the masked encoder, full encoder, and decoder.</p></dd>

    <dt><code>vaeac.latent_dim</code></dt>
<dd><p>Positive integer (default is <code>8</code>). The number of dimensions in the latent space.</p></dd>

    <dt><code>vaeac.lr</code></dt>
<dd><p>Positive numeric (default is <code>0.001</code>). The learning rate used in the <code><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">torch::optim_adam()</a></code> optimizer.</p></dd>

    <dt><code>vaeac.activation_function</code></dt>
<dd><p>An <code><a href="https://rdrr.io/pkg/torch/man/nn_module.html" class="external-link">torch::nn_module()</a></code> representing an activation function such as, e.g.,
<code><a href="https://rdrr.io/pkg/torch/man/nn_relu.html" class="external-link">torch::nn_relu()</a></code> (default), <code><a href="https://rdrr.io/pkg/torch/man/nn_leaky_relu.html" class="external-link">torch::nn_leaky_relu()</a></code>, <code><a href="https://rdrr.io/pkg/torch/man/nn_selu.html" class="external-link">torch::nn_selu()</a></code>, or <code><a href="https://rdrr.io/pkg/torch/man/nn_sigmoid.html" class="external-link">torch::nn_sigmoid()</a></code>.</p></dd>

    <dt><code>vaeac.n_vaeacs_initialize</code></dt>
<dd><p>Positive integer (default is <code>4</code>). The number of different vaeac models to initiate
in the start. Pick the best performing one after <code>vaeac.extra_parameters$epochs_initiation_phase</code>
epochs (default is <code>2</code>) and continue training that one.</p></dd>

    <dt><code>vaeac.epochs</code></dt>
<dd><p>Positive integer (default is <code>100</code>). The number of epochs to train the final vaeac model.
This includes <code>vaeac.extra_parameters$epochs_initiation_phase</code>, where the default is <code>2</code>.</p></dd>

    <dt><code>vaeac.extra_parameters</code></dt>
<dd><p>Named list with extra parameters to the <code>vaeac</code> approach. See
<code><a href="vaeac_get_extra_para_default.html">vaeac_get_extra_para_default()</a></code> for description of possible additional parameters and their default values.</p></dd>

    <dt><code>categorical.joint_prob_dt</code></dt>
<dd><p>Data.table. (Optional)
Containing the joint probability distribution for each combination of feature
values.
<code>NULL</code> means it is estimated from the <code>x_train</code> and <code>x_explain</code>.</p></dd>

    <dt><code>categorical.epsilon</code></dt>
<dd><p>Numeric value. (Optional)
If <code>joint_probability_dt</code> is not supplied, probabilities/frequencies are
estimated using <code>x_train</code>. If certain observations occur in <code>x_train</code> and NOT in <code>x_explain</code>,
then epsilon is used as the proportion of times that these observations occurs in the training data.
In theory, this proportion should be zero, but this causes an error later in the Shapley computation.</p></dd>

    <dt><code>regression.model</code></dt>
<dd><p>A <code>tidymodels</code> object of class <code>model_specs</code>. Default is a linear regression model, i.e.,
<code><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">parsnip::linear_reg()</a></code>. See <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">tidymodels</a> for all possible models,
and see the vignette for how to add new/own models. Note, to make it easier to call <code>explain()</code> from Python, the
<code>regression.model</code> parameter can also be a string specifying the model which will be parsed and evaluated. For
example, <code>"parsnip::rand_forest(mtry = hardhat::tune(), trees = 100, engine = "ranger", mode = "regression")"</code>
is also a valid input. It is essential to include the package prefix if the package is not loaded.</p></dd>

    <dt><code>regression.tune_values</code></dt>
<dd><p>Either <code>NULL</code> (default), a data.frame/data.table/tibble, or a function.
The data.frame must contain the possible hyperparameter value combinations to try.
The column names must match the names of the tuneable parameters specified in <code>regression.model</code>.
If <code>regression.tune_values</code> is a function, then it should take one argument <code>x</code> which is the training data
for the current combination/coalition and returns a data.frame/data.table/tibble with the properties described above.
Using a function allows the hyperparameter values to change based on the size of the combination. See the regression
vignette for several examples.
Note, to make it easier to call <code>explain()</code> from Python, the <code>regression.tune_values</code> can also be a string
containing an R function. For example,
<code>"function(x) return(dials::grid_regular(dials::mtry(c(1, ncol(x)))), levels = 3))"</code> is also a valid input.
It is essential to include the package prefix if the package is not loaded.</p></dd>

    <dt><code>regression.vfold_cv_para</code></dt>
<dd><p>Either <code>NULL</code> (default) or a named list containing
the parameters to be sent to <code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">rsample::vfold_cv()</a></code>. See the regression vignette for
several examples.</p></dd>

    <dt><code>regression.recipe_func</code></dt>
<dd><p>Either <code>NULL</code> (default) or a function that that takes in a <code><a href="https://recipes.tidymodels.org/reference/recipe.html" class="external-link">recipes::recipe()</a></code>
object and returns a modified <code><a href="https://recipes.tidymodels.org/reference/recipe.html" class="external-link">recipes::recipe()</a></code> with potentially additional recipe steps. See the regression
vignette for several examples.
Note, to make it easier to call <code>explain()</code> from Python, the <code>regression.recipe_func</code> can also be a string
containing an R function. For example,
<code>"function(recipe) return(recipes::step_ns(recipe, recipes::all_numeric_predictors(), deg_free = 2))"</code> is also
a valid input. It is essential to include the package prefix if the package is not loaded.</p></dd>

    <dt><code>regression.surrogate_n_comb</code></dt>
<dd><p>Integer (default is <code>internal$parameters$used_n_combinations</code>) specifying the
number of unique combinations/coalitions to apply to each training observation. Maximum allowed value is
"<code>internal$parameters$used_n_combinations</code> - 2". By default, we use all coalitions, but this can take a lot of memory
in larger dimensions. Note that by "all", we mean all coalitions chosen by <code>shapr</code> to be used. This will be all
\(2^{n_{\text{features}}}\) coalitions (minus empty and grand coalition) if <code>shapr</code> is in the exact mode. If the
user sets a lower value than <code>internal$parameters$used_n_combinations</code>, then we sample this amount of unique
coalitions separately for each training observations. That is, on average, all coalitions should be equally trained.</p></dd>

    <dt><code>timeseries.fixed_sigma_vec</code></dt>
<dd><p>Numeric. (Default = 2)
Represents the kernel bandwidth in the distance computation. TODO: What length should it have? 1?</p></dd>

    <dt><code>timeseries.bounds</code></dt>
<dd><p>Numeric vector of length two. (Default = c(NULL, NULL))
If one or both of these bounds are not NULL, we restrict the sampled time series to be
between these bounds.
This is useful if the underlying time series are scaled between 0 and 1, for example.</p></dd>


</dl></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>Object of class <code>c("shapr", "list")</code>. Contains the following items:</p><dl><dt>shapley_values</dt>
<dd><p>data.table with the estimated Shapley values</p></dd>

<dt>internal</dt>
<dd><p>List with the different parameters, data and functions used internally</p></dd>

<dt>pred_explain</dt>
<dd><p>Numeric vector with the predictions for the explained observations</p></dd>

<dt>MSEv</dt>
<dd><p>List with the values of the MSEv evaluation criterion for the approach.</p></dd>


</dl><p><code>shapley_values</code> is a data.table where the number of rows equals
the number of observations you'd like to explain, and the number of columns equals <code>m +1</code>,
where <code>m</code> equals the total number of features in your model.</p>
<p>If <code>shapley_values[i, j + 1] &gt; 0</code> it indicates that the j-th feature increased the prediction for
the i-th observation. Likewise, if <code>shapley_values[i, j + 1] &lt; 0</code> it indicates that the j-th feature
decreased the prediction for the i-th observation.
The magnitude of the value is also important to notice. E.g. if <code>shapley_values[i, k + 1]</code> and
<code>shapley_values[i, j + 1]</code> are greater than <code>0</code>, where <code>j != k</code>, and
<code>shapley_values[i, k + 1]</code> &gt; <code>shapley_values[i, j + 1]</code> this indicates that feature
<code>j</code> and <code>k</code> both increased the value of the prediction, but that the effect of the k-th
feature was larger than the j-th feature.</p>
<p>The first column in <code>dt</code>, called <code>none</code>, is the prediction value not assigned to any of the features
(\(\phi\)<sub>0</sub>).
It's equal for all observations and set by the user through the argument <code>prediction_zero</code>.
The difference between the prediction and <code>none</code> is distributed among the other features.
In theory this value should be the expected prediction without conditioning on any features.
Typically we set this value equal to the mean of the response variable in our training data, but other choices
such as the mean of the predictions in the training data are also reasonable.</p>
    </div>
    <div id="details">
    <h2>Details</h2>
    <p>The most important thing to notice is that <code>shapr</code> has implemented eight different
Monte Carlo-based approaches for estimating the conditional distributions of the data, namely <code>"empirical"</code>,
<code>"gaussian"</code>, <code>"copula"</code>, <code>"ctree"</code>, <code>"vaeac"</code>, <code>"categorical"</code>, <code>"timeseries"</code>, and <code>"independence"</code>.
<code>shapr</code> has also implemented two regression-based approaches <code>"regression_separate"</code> and <code>"regression_surrogate"</code>,
and see the separate vignette on the regression-based approaches for more information.
In addition, the user also has the option of combining the different Monte Carlo-based approaches.
E.g., if you're in a situation where you have trained a model that consists of 10 features,
and you'd like to use the <code>"gaussian"</code> approach when you condition on a single feature,
the <code>"empirical"</code> approach if you condition on 2-5 features, and <code>"copula"</code> version
if you condition on more than 5 features this can be done by simply passing
<code>approach = c("gaussian", rep("empirical", 4), rep("copula", 4))</code>. If
<code>"approach[i]" = "gaussian"</code> means that you'd like to use the <code>"gaussian"</code> approach
when conditioning on <code>i</code> features. Conditioning on all features needs no approach as that is given
by the complete prediction itself, and should thus not be part of the vector.</p>
<p>For <code>approach="ctree"</code>, <code>n_samples</code> corresponds to the number of samples
from the leaf node (see an exception related to the <code>sample</code> argument).
For <code>approach="empirical"</code>, <code>n_samples</code> is  the \(K\) parameter in equations (14-15) of
Aas et al. (2021), i.e. the maximum number of observations (with largest weights) that is used, see also the
<code>empirical.eta</code> argument.</p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Aas, K., Jullum, M., &amp; L&lt;U+00F8&gt;land, A. (2021). Explaining individual predictions when features are dependent:
More accurate approximations to Shapley values. Artificial Intelligence, 298, 103502.</p>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>Martin Jullum, Lars Henry Berge Olsen</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Load example data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"airquality"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">airquality</span> <span class="op">&lt;-</span> <span class="va">airquality</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html" class="external-link">complete.cases</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span>, <span class="op">]</span></span></span>
<span class="r-in"><span><span class="va">x_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">y_var</span> <span class="op">&lt;-</span> <span class="st">"Ozone"</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Split data into test- and training data</span></span></span>
<span class="r-in"><span><span class="va">data_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">airquality</span>, <span class="op">-</span><span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">data_explain</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">airquality</span>, <span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">data_train</span><span class="op">[</span>, <span class="va">x_var</span><span class="op">]</span></span></span>
<span class="r-in"><span><span class="va">x_explain</span> <span class="op">&lt;-</span> <span class="va">data_explain</span><span class="op">[</span>, <span class="va">x_var</span><span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fit a linear model</span></span></span>
<span class="r-in"><span><span class="va">lm_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">y_var</span>, <span class="st">" ~ "</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">x_var</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">lm_formula</span>, data <span class="op">=</span> <span class="va">data_train</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Explain predictions</span></span></span>
<span class="r-in"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data_train</span><span class="op">[</span>, <span class="va">y_var</span><span class="op">]</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Empirical approach</span></span></span>
<span class="r-in"><span><span class="va">explain1</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  n_samples <span class="op">=</span> <span class="fl">1e2</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 2 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Gaussian approach</span></span></span>
<span class="r-in"><span><span class="va">explain2</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"gaussian"</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  n_samples <span class="op">=</span> <span class="fl">1e2</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 10 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Gaussian copula approach</span></span></span>
<span class="r-in"><span><span class="va">explain3</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"copula"</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  n_samples <span class="op">=</span> <span class="fl">1e2</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 10 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># ctree approach</span></span></span>
<span class="r-in"><span><span class="va">explain4</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"ctree"</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  n_samples <span class="op">=</span> <span class="fl">1e2</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 10 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Combined approach</span></span></span>
<span class="r-in"><span><span class="va">approach</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>, <span class="st">"gaussian"</span>, <span class="st">"empirical"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">explain5</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="va">approach</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  n_samples <span class="op">=</span> <span class="fl">1e2</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 10 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Print the Shapley values</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">explain1</span><span class="op">$</span><span class="va">shapley_values</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        none   Solar.R       Wind       Temp     Month</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>       &lt;num&gt;     &lt;num&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1: 42.78704  6.124296 -20.137653  -5.033967 -5.987303</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2: 42.78704 -1.470838  11.525868  -9.487924 -5.597657</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3: 42.78704  3.524599  -5.335059 -16.599988 -8.703929</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Plot the results</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"ggplot2"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explain1</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explain1</span>, plot_type <span class="op">=</span> <span class="st">"waterfall"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-plt img"><img src="explain-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Group-wise explanations</span></span></span>
<span class="r-in"><span><span class="va">group_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Temp"</span>, <span class="st">"Month"</span><span class="op">)</span>, B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Wind"</span>, <span class="st">"Solar.R"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">explain_groups</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  group <span class="op">=</span> <span class="va">group_list</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  n_samples <span class="op">=</span> <span class="fl">1e2</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 2 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">explain_groups</span><span class="op">$</span><span class="va">shapley_values</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        none         A          B</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>       &lt;num&gt;     &lt;num&gt;      &lt;num&gt;</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1: 42.78704 -11.63856 -13.396062</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2: 42.78704 -10.36824   5.337683</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3: 42.78704 -25.79874  -1.315633</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Separate and surrogate regression approaches with linear regression models.</span></span></span>
<span class="r-in"><span><span class="co"># More complex regression models can be used, and we can use CV to</span></span></span>
<span class="r-in"><span><span class="co"># tune the hyperparameters of the regression models and preprocess</span></span></span>
<span class="r-in"><span><span class="co"># the data before sending it to the model. See the regression vignette</span></span></span>
<span class="r-in"><span><span class="co"># (Shapley value explanations using the regression paradigm) for more</span></span></span>
<span class="r-in"><span><span class="co"># details about the `regression_separate` and `regression_surrogate` approaches.</span></span></span>
<span class="r-in"><span><span class="va">explain_separate_lm</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span></span>
<span class="r-in"><span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 2 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">explain_surrogate_lm</span> <span class="op">&lt;-</span> <span class="fu">explain</span><span class="op">(</span></span></span>
<span class="r-in"><span>  model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span></span>
<span class="r-in"><span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span></span>
<span class="r-in"><span>  prediction_zero <span class="op">=</span> <span class="va">p</span>,</span></span>
<span class="r-in"><span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span></span>
<span class="r-in"><span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Setting parameter 'n_batches' to 2 as a fair trade-off between memory consumption and computation time.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Nikolai Sellereite, Martin Jullum, Lars Henry Berge Olsen, Annabelle Redelmeier, Jon Lachmann, Norsk Regnesentral.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

      </footer></div>






  </body></html>

